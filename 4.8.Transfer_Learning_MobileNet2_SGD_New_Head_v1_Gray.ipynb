{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.8.Transfer_Learning_MobileNet2_SGD_New_Head_v1_Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn\n",
    "#!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "from tensorflow_examples.lite.model_maker.core.data_util.image_dataloader import ImageClassifierDataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empezamos el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pyimagesearch.preprocessing import ImageToArrayPreprocessor\n",
    "from pyimagesearch.preprocessing import AspectAwarePreprocessor\n",
    "from pyimagesearch.datasets import SimpleDatasetLoader\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leemos la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "path_train = 'data_' + str(img_size) + '/train'\n",
    "path_validation = 'data_' + str(img_size) + '/validation'\n",
    "path_checkpoints = 'checkpoint_MobileNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etiquetas del entrenamiento\n",
      "['10', '100', '20', '200', '50']\n",
      "codificando etiquetas\n",
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "imagePaths_train = list(paths.list_images(path_train))\n",
    "imagePaths_validation = list(paths.list_images(path_validation))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths_train]\n",
    "classNames = [str(x) for x in np.unique(classNames)]\n",
    "\n",
    "print(\"etiquetas del entrenamiento\")\n",
    "print(classNames)\n",
    "\n",
    "#Códificando las etiquetas en númerops\n",
    "print(\"codificando etiquetas\")\n",
    "le = LabelEncoder()\n",
    "classNames_ids = le.fit_transform(classNames)\n",
    "print(classNames_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iap = ImageToArrayPreprocessor()\n",
    "sdl = SimpleDatasetLoader(preprocessors=[iap])\n",
    "\n",
    "print('Cargando data para el entrenamiento')\n",
    "data_train, labels_train = sdl.load(imagePaths_train, verbose=5000)\n",
    "\n",
    "print('Cargando data para la validación')\n",
    "data_validation, labels_validation = sdl.load(imagePaths_validation, verbose=500)\n",
    "\n",
    "print('Binarizando los labels')\n",
    "labels_train = LabelBinarizer().fit_transform(labels_train)\n",
    "labels_validation = LabelBinarizer().fit_transform(labels_validation)\n",
    "\n",
    "print('Carga terminada')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando el modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_size,img_size,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congelamos las capas para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos la nueva cabecera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos varios modelos para luego realizar un ensamblaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ensembles = 'ensembles_MobileNetV2'\n",
    "batch_size = 32\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print('Normalizando los datos')\n",
    "data_train = data_train.astype(\"float\") / 255.0\n",
    "data_validation = data_validation.astype(\"float\") / 255.0\n",
    "\n",
    "print('Generando la data para el entrenamiento')\n",
    "aug_train = ImageDataGenerator()\n",
    "aug_train.fit(data_train)\n",
    "train_generator = aug_train.flow(data_train, labels_train, batch_size=batch_size)\n",
    "\n",
    "aug_validation = ImageDataGenerator()\n",
    "aug_validation.fit(data_validation)\n",
    "validation_generator = aug_validation.flow(data_validation, labels_validation, batch_size=batch_size)\n",
    "print('Terminado')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train = ImageDataGenerator(rescale=1. / 255)\n",
    "#aug_train.fit(data_train)\n",
    "train_generator = aug_train.flow_from_directory(path_train,\n",
    "                                                target_size=(img_size, img_size),\n",
    "                                                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_validation = ImageDataGenerator(rescale=1. / 255)\n",
    "#aug_validation.fit(data_validation)\n",
    "validation_generator = aug_validation.flow_from_directory(path_validation,\n",
    "                                                          target_size=(img_size, img_size),\n",
    "                                                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([base_model,\n",
    "                             GlobalAveragePooling2D(),\n",
    "                             Dense(1024, activation='relu'),\n",
    "                             Dense(len(classNames_ids), activation='softmax')\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = Adam(learning_rate=0.0001)\n",
    "#optimizer = RMSprop(learning_rate=0.0001)\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics=[\"accuracy\"]\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.sep.join([path_checkpoints, \n",
    "                          'epoch-{epoch:03d}-val_loss:{val_loss:.4f}-val_accuracy:{val_accuracy:.4f}.hdf5'])\n",
    "checkpoint = ModelCheckpoint(fname,\n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True,\n",
    "                             mode='max',\n",
    "                             verbose=1)\n",
    "callbacks = [checkpoint]\n",
    "#callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#entrenando el modelo\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=len(train_generator),\n",
    "                              validation_data=validation_generator,\n",
    "                              epochs = epochs,\n",
    "                              callbacks=callbacks,\n",
    "                              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardando el modelo\n",
    "p = [path_ensembles, \"model_220_SGD.model\"]\n",
    "model.save(os.path.sep.join(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluando el modelo\n",
    "predictions = model.predict(data_validation, batch_size=batch_size)\n",
    "print(classification_report(labels_validation.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1),\n",
    "                            target_names=classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.ylim([min(plt.ylim()),1])\n",
    "plt.ylim([0,1.1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "#plt.ylim([0,1.0])\n",
    "plt.ylim([0,20])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomando 25 imágenes de validación y observando el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageClassifierDataLoader.from_folder(path_validation)\n",
    "\n",
    "def get_label_color(val1, val2):\n",
    "  if val1 == val2:\n",
    "    return 'black'\n",
    "  else:\n",
    "    return 'red'\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i, (image, label) in enumerate(test_data.dataset.take(100)):\n",
    "    ax = plt.subplot(10, 10, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
    "    \n",
    "    # predict\n",
    "    swapped = np.moveaxis(image, 0, 1)\n",
    "    arr4d = np.expand_dims(swapped, 0)\n",
    "    id_predict = np.argmax(model.predict(arr4d))\n",
    "    predict_label = classNames[id_predict]\n",
    "    \n",
    "    color = get_label_color(predict_label, test_data.index_to_label[label.numpy()])\n",
    "    #color = 'black'\n",
    "    ax.xaxis.label.set_color(color)\n",
    "    plt.xlabel('Predicted: %s' % predict_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
