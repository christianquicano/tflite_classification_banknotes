{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7.Transfer_Learning_MobileNet2_SGD_New_Head_v2_new_augmentation_100_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn\n",
    "#!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "from tensorflow_examples.lite.model_maker.core.data_util.image_dataloader import ImageClassifierDataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empezamos el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pyimagesearch.preprocessing import ImageToArrayPreprocessor\n",
    "from pyimagesearch.preprocessing import AspectAwarePreprocessor\n",
    "from pyimagesearch.datasets import SimpleDatasetLoader\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leemos la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "path_train = 'data_' + str(img_size) + '/train'\n",
    "path_validation = 'data_' + str(img_size) + '/validation'\n",
    "path_checkpoints = 'checkpoint_MobileNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etiquetas del entrenamiento\n",
      "['100_espalda', '100_frente', '10_espalda', '10_frente', '200_espalda', '200_frente', '20_espalda', '20_frente', '50_espalda', '50_frente']\n",
      "codificando etiquetas\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "imagePaths_train = list(paths.list_images(path_train))\n",
    "imagePaths_validation = list(paths.list_images(path_validation))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths_train]\n",
    "classNames = [str(x) for x in np.unique(classNames)]\n",
    "\n",
    "print(\"etiquetas del entrenamiento\")\n",
    "print(classNames)\n",
    "\n",
    "#Códificando las etiquetas en númerops\n",
    "print(\"codificando etiquetas\")\n",
    "le = LabelEncoder()\n",
    "classNames_ids = le.fit_transform(classNames)\n",
    "print(classNames_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iap = ImageToArrayPreprocessor()\n",
    "sdl = SimpleDatasetLoader(preprocessors=[iap])\n",
    "\n",
    "print('Cargando data para el entrenamiento')\n",
    "data_train, labels_train = sdl.load(imagePaths_train, verbose=5000)\n",
    "\n",
    "print('Cargando data para la validación')\n",
    "data_validation, labels_validation = sdl.load(imagePaths_validation, verbose=500)\n",
    "\n",
    "print('Binarizando los labels')\n",
    "labels_train = LabelBinarizer().fit_transform(labels_train)\n",
    "labels_validation = LabelBinarizer().fit_transform(labels_validation)\n",
    "\n",
    "print('Carga terminada')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando el modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_size,img_size,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congelamos las capas para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos la nueva cabecera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos varios modelos para luego realizar un ensamblaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ensembles = 'ensembles_MobileNetV2'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print('Normalizando los datos')\n",
    "data_train = data_train.astype(\"float\") / 255.0\n",
    "data_validation = data_validation.astype(\"float\") / 255.0\n",
    "\n",
    "print('Generando la data para el entrenamiento')\n",
    "aug_train = ImageDataGenerator()\n",
    "aug_train.fit(data_train)\n",
    "train_generator = aug_train.flow(data_train, labels_train, batch_size=batch_size)\n",
    "\n",
    "aug_validation = ImageDataGenerator()\n",
    "aug_validation.fit(data_validation)\n",
    "validation_generator = aug_validation.flow(data_validation, labels_validation, batch_size=batch_size)\n",
    "print('Terminado')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3360 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "aug_train = ImageDataGenerator(rescale=1. / 255)\n",
    "#aug_train.fit(data_train)\n",
    "train_generator = aug_train.flow_from_directory(path_train,\n",
    "                                                target_size=(img_size, img_size),\n",
    "                                                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2671 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "aug_validation = ImageDataGenerator(rescale=1. / 255)\n",
    "#aug_validation.fit(data_validation)\n",
    "validation_generator = aug_validation.flow_from_directory(path_validation,\n",
    "                                                          target_size=(img_size, img_size),\n",
    "                                                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                              base_model,\n",
    "                             GlobalAveragePooling2D(),\n",
    "                             Dense(1024, activation='relu'),\n",
    "                             Dense(len(classNames_ids), activation='softmax')\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              1311744   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,579,978\n",
      "Trainable params: 3,545,866\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = Adam(learning_rate=0.0001)\n",
    "#optimizer = RMSprop(learning_rate=0.0001)\n",
    "optimizer = SGD(learning_rate=0.0001)\n",
    "\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics=[\"accuracy\"]\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.sep.join([path_checkpoints, \n",
    "                          'epoch-{epoch:03d}-val_loss:{val_loss:.4f}-val_accuracy:{val_accuracy:.4f}.hdf5'])\n",
    "checkpoint = ModelCheckpoint(fname,\n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True,\n",
    "                             mode='max',\n",
    "                             verbose=1)\n",
    "#callbacks = [checkpoint]\n",
    "callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "105/105 [==============================] - 97s 928ms/step - loss: 2.2362 - accuracy: 0.1690 - val_loss: 2.3973 - val_accuracy: 0.1060\n",
      "Epoch 2/120\n",
      "105/105 [==============================] - 97s 927ms/step - loss: 2.1413 - accuracy: 0.2295 - val_loss: 2.3736 - val_accuracy: 0.1138\n",
      "Epoch 3/120\n",
      "105/105 [==============================] - 98s 929ms/step - loss: 2.0655 - accuracy: 0.2908 - val_loss: 2.3512 - val_accuracy: 0.1269\n",
      "Epoch 4/120\n",
      "105/105 [==============================] - 97s 927ms/step - loss: 1.9855 - accuracy: 0.3452 - val_loss: 2.3303 - val_accuracy: 0.1367\n",
      "Epoch 5/120\n",
      "105/105 [==============================] - 97s 927ms/step - loss: 1.9090 - accuracy: 0.4173 - val_loss: 2.3098 - val_accuracy: 0.1494\n",
      "Epoch 6/120\n",
      "105/105 [==============================] - 97s 923ms/step - loss: 1.8245 - accuracy: 0.4908 - val_loss: 2.2899 - val_accuracy: 0.1595\n",
      "Epoch 7/120\n",
      "105/105 [==============================] - 97s 920ms/step - loss: 1.7578 - accuracy: 0.5503 - val_loss: 2.2697 - val_accuracy: 0.1707\n",
      "Epoch 8/120\n",
      "105/105 [==============================] - 97s 920ms/step - loss: 1.6841 - accuracy: 0.6083 - val_loss: 2.2495 - val_accuracy: 0.1805\n",
      "Epoch 9/120\n",
      "105/105 [==============================] - 97s 919ms/step - loss: 1.6089 - accuracy: 0.6685 - val_loss: 2.2292 - val_accuracy: 0.1932\n",
      "Epoch 10/120\n",
      "105/105 [==============================] - 97s 926ms/step - loss: 1.5434 - accuracy: 0.7030 - val_loss: 2.2087 - val_accuracy: 0.2089\n",
      "Epoch 11/120\n",
      "105/105 [==============================] - 98s 931ms/step - loss: 1.4766 - accuracy: 0.7315 - val_loss: 2.1870 - val_accuracy: 0.2213\n",
      "Epoch 12/120\n",
      "105/105 [==============================] - 98s 933ms/step - loss: 1.3996 - accuracy: 0.7774 - val_loss: 2.1654 - val_accuracy: 0.2370\n",
      "Epoch 13/120\n",
      "105/105 [==============================] - 98s 929ms/step - loss: 1.3348 - accuracy: 0.7946 - val_loss: 2.1440 - val_accuracy: 0.2520\n",
      "Epoch 14/120\n",
      "105/105 [==============================] - 98s 931ms/step - loss: 1.2647 - accuracy: 0.8268 - val_loss: 2.1215 - val_accuracy: 0.2587\n",
      "Epoch 15/120\n",
      "105/105 [==============================] - 98s 929ms/step - loss: 1.2074 - accuracy: 0.8557 - val_loss: 2.1011 - val_accuracy: 0.2699\n",
      "Epoch 16/120\n",
      "105/105 [==============================] - 97s 928ms/step - loss: 1.1387 - accuracy: 0.8786 - val_loss: 2.0814 - val_accuracy: 0.2763\n",
      "Epoch 17/120\n",
      "105/105 [==============================] - 98s 930ms/step - loss: 1.0807 - accuracy: 0.8932 - val_loss: 2.0618 - val_accuracy: 0.2909\n",
      "Epoch 18/120\n",
      "105/105 [==============================] - 98s 933ms/step - loss: 1.0269 - accuracy: 0.8985 - val_loss: 2.0433 - val_accuracy: 0.3051\n",
      "Epoch 19/120\n",
      "105/105 [==============================] - 98s 930ms/step - loss: 0.9693 - accuracy: 0.9071 - val_loss: 2.0249 - val_accuracy: 0.3156\n",
      "Epoch 20/120\n",
      "105/105 [==============================] - 97s 923ms/step - loss: 0.9152 - accuracy: 0.9250 - val_loss: 2.0070 - val_accuracy: 0.3280\n",
      "Epoch 21/120\n",
      "105/105 [==============================] - 97s 928ms/step - loss: 0.8629 - accuracy: 0.9298 - val_loss: 1.9903 - val_accuracy: 0.3328\n",
      "Epoch 22/120\n",
      "105/105 [==============================] - 98s 930ms/step - loss: 0.8134 - accuracy: 0.9393 - val_loss: 1.9736 - val_accuracy: 0.3433\n",
      "Epoch 23/120\n",
      "105/105 [==============================] - 98s 935ms/step - loss: 0.7674 - accuracy: 0.9491 - val_loss: 1.9581 - val_accuracy: 0.3471\n",
      "Epoch 24/120\n",
      "105/105 [==============================] - 98s 931ms/step - loss: 0.7261 - accuracy: 0.9536 - val_loss: 1.9438 - val_accuracy: 0.3560\n",
      "Epoch 25/120\n",
      "105/105 [==============================] - 98s 932ms/step - loss: 0.6808 - accuracy: 0.9563 - val_loss: 1.9295 - val_accuracy: 0.3617\n",
      "Epoch 26/120\n",
      "105/105 [==============================] - 97s 927ms/step - loss: 0.6433 - accuracy: 0.9586 - val_loss: 1.9162 - val_accuracy: 0.3643\n",
      "Epoch 27/120\n",
      "105/105 [==============================] - 97s 928ms/step - loss: 0.6130 - accuracy: 0.9631 - val_loss: 1.9031 - val_accuracy: 0.3677\n",
      "Epoch 28/120\n",
      "105/105 [==============================] - 96s 918ms/step - loss: 0.5845 - accuracy: 0.9664 - val_loss: 1.8906 - val_accuracy: 0.3706\n",
      "Epoch 29/120\n",
      "105/105 [==============================] - 97s 926ms/step - loss: 0.5531 - accuracy: 0.9679 - val_loss: 1.8778 - val_accuracy: 0.3744\n",
      "Epoch 30/120\n",
      "105/105 [==============================] - 98s 930ms/step - loss: 0.5193 - accuracy: 0.9676 - val_loss: 1.8668 - val_accuracy: 0.3763\n",
      "Epoch 31/120\n",
      "105/105 [==============================] - 97s 923ms/step - loss: 0.4997 - accuracy: 0.9744 - val_loss: 1.8551 - val_accuracy: 0.3830\n",
      "Epoch 32/120\n",
      "105/105 [==============================] - 97s 923ms/step - loss: 0.4695 - accuracy: 0.9759 - val_loss: 1.8446 - val_accuracy: 0.3860\n",
      "Epoch 33/120\n",
      "105/105 [==============================] - 97s 925ms/step - loss: 0.4488 - accuracy: 0.9774 - val_loss: 1.8337 - val_accuracy: 0.3897\n",
      "Epoch 34/120\n",
      "105/105 [==============================] - 98s 932ms/step - loss: 0.4317 - accuracy: 0.9795 - val_loss: 1.8243 - val_accuracy: 0.3927\n",
      "Epoch 35/120\n",
      "105/105 [==============================] - 98s 931ms/step - loss: 0.4136 - accuracy: 0.9792 - val_loss: 1.8143 - val_accuracy: 0.3965\n",
      "Epoch 36/120\n",
      "105/105 [==============================] - 98s 933ms/step - loss: 0.3858 - accuracy: 0.9824 - val_loss: 1.8056 - val_accuracy: 0.3980\n",
      "Epoch 37/120\n",
      "105/105 [==============================] - 97s 926ms/step - loss: 0.3653 - accuracy: 0.9807 - val_loss: 1.7976 - val_accuracy: 0.4028\n",
      "Epoch 38/120\n",
      "105/105 [==============================] - 98s 929ms/step - loss: 0.3562 - accuracy: 0.9827 - val_loss: 1.7895 - val_accuracy: 0.4040\n",
      "Epoch 39/120\n",
      "105/105 [==============================] - 98s 931ms/step - loss: 0.3351 - accuracy: 0.9839 - val_loss: 1.7817 - val_accuracy: 0.4040\n",
      "Epoch 40/120\n",
      "105/105 [==============================] - 98s 929ms/step - loss: 0.3193 - accuracy: 0.9866 - val_loss: 1.7747 - val_accuracy: 0.4055\n",
      "Epoch 41/120\n",
      "105/105 [==============================] - 98s 930ms/step - loss: 0.3068 - accuracy: 0.9869 - val_loss: 1.7674 - val_accuracy: 0.4088\n",
      "Epoch 42/120\n",
      "105/105 [==============================] - 97s 927ms/step - loss: 0.2868 - accuracy: 0.9872 - val_loss: 1.7603 - val_accuracy: 0.4100\n",
      "Epoch 43/120\n",
      "105/105 [==============================] - 97s 920ms/step - loss: 0.2824 - accuracy: 0.9884 - val_loss: 1.7531 - val_accuracy: 0.4122\n",
      "Epoch 44/120\n",
      "105/105 [==============================] - 98s 935ms/step - loss: 0.2707 - accuracy: 0.9890 - val_loss: 1.7470 - val_accuracy: 0.4133\n",
      "Epoch 45/120\n",
      "105/105 [==============================] - 97s 922ms/step - loss: 0.2596 - accuracy: 0.9884 - val_loss: 1.7407 - val_accuracy: 0.4141\n",
      "Epoch 46/120\n",
      "105/105 [==============================] - 98s 930ms/step - loss: 0.2448 - accuracy: 0.9929 - val_loss: 1.7351 - val_accuracy: 0.4167\n",
      "Epoch 47/120\n",
      "105/105 [==============================] - 98s 931ms/step - loss: 0.2423 - accuracy: 0.9896 - val_loss: 1.7290 - val_accuracy: 0.4167\n",
      "Epoch 48/120\n",
      "105/105 [==============================] - 98s 930ms/step - loss: 0.2238 - accuracy: 0.9946 - val_loss: 1.7236 - val_accuracy: 0.4182\n",
      "Epoch 49/120\n",
      "105/105 [==============================] - 97s 924ms/step - loss: 0.2232 - accuracy: 0.9929 - val_loss: 1.7179 - val_accuracy: 0.4178\n",
      "Epoch 50/120\n",
      "105/105 [==============================] - 97s 922ms/step - loss: 0.2122 - accuracy: 0.9920 - val_loss: 1.7125 - val_accuracy: 0.4189\n",
      "Epoch 51/120\n",
      "105/105 [==============================] - 98s 937ms/step - loss: 0.2113 - accuracy: 0.9932 - val_loss: 1.7075 - val_accuracy: 0.4189\n",
      "Epoch 52/120\n",
      "105/105 [==============================] - 98s 930ms/step - loss: 0.1935 - accuracy: 0.9961 - val_loss: 1.7036 - val_accuracy: 0.4193\n",
      "Epoch 53/120\n",
      "105/105 [==============================] - 98s 930ms/step - loss: 0.1910 - accuracy: 0.9932 - val_loss: 1.6990 - val_accuracy: 0.4197\n",
      "Epoch 54/120\n",
      "105/105 [==============================] - 98s 932ms/step - loss: 0.1888 - accuracy: 0.9911 - val_loss: 1.6944 - val_accuracy: 0.4193\n",
      "Epoch 55/120\n",
      "105/105 [==============================] - 97s 928ms/step - loss: 0.1803 - accuracy: 0.9958 - val_loss: 1.6899 - val_accuracy: 0.4212\n",
      "Epoch 56/120\n",
      "105/105 [==============================] - 97s 923ms/step - loss: 0.1757 - accuracy: 0.9946 - val_loss: 1.6850 - val_accuracy: 0.4219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/120\n",
      " 25/105 [======>.......................] - ETA: 1:08 - loss: 0.1790 - accuracy: 0.9900"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-504ae8f1eb26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               verbose = 1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2815\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2816\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2817\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2819\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1840\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1841\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1918\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1919\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1920\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 120\n",
    "#entrenando el modelo\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=len(train_generator),\n",
    "                              validation_data=validation_generator,\n",
    "                              epochs = epochs,\n",
    "                              callbacks=callbacks,\n",
    "                              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardando el modelo\n",
    "p = [path_ensembles, \"model_head_v2_new_augmentation_400_SGD.model\"]\n",
    "model.save(os.path.sep.join(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluando el modelo\n",
    "predictions = model.predict(data_validation, batch_size=batch_size)\n",
    "print(classification_report(labels_validation.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1),\n",
    "                            target_names=classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.ylim([min(plt.ylim()),1])\n",
    "plt.ylim([0,1.1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "#plt.ylim([0,1.0])\n",
    "plt.ylim([0,20])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomando 25 imágenes de validación y observando el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageClassifierDataLoader.from_folder(path_validation)\n",
    "\n",
    "def get_label_color(val1, val2):\n",
    "  if val1 == val2:\n",
    "    return 'black'\n",
    "  else:\n",
    "    return 'red'\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i, (image, label) in enumerate(test_data.dataset.take(100)):\n",
    "    ax = plt.subplot(10, 10, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
    "    \n",
    "    # predict\n",
    "    swapped = np.moveaxis(image, 0, 1)\n",
    "    arr4d = np.expand_dims(swapped, 0)\n",
    "    id_predict = np.argmax(model.predict(arr4d))\n",
    "    predict_label = classNames[id_predict]\n",
    "    \n",
    "    color = get_label_color(predict_label, test_data.index_to_label[label.numpy()])\n",
    "    #color = 'black'\n",
    "    ax.xaxis.label.set_color(color)\n",
    "    plt.xlabel('Predicted: %s' % predict_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
