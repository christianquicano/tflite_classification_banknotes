{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1_Extraer_Caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install imutils\n",
    "#!pip install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pyimagesearch.io import HDF5DatasetWriter\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import argparse\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 32\n",
    "buffer_size = 1000 #control the number of extracted feature store in memory\n",
    "path_train = 'data_' + str(img_size) + '/train'\n",
    "path_validation = 'data_' + str(img_size) + '/validation'\n",
    "path_output_train_hdf5 = 'HDF5/MobileNetV2_train.hdf5'\n",
    "path_output_validation_hdf5 = 'HDF5/MobileNetV2_validation.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargando las imágenes\n",
    "imagePaths_train = list(paths.list_images(path_train))\n",
    "imagePaths_validation = list(paths.list_images(path_validation))\n",
    "#moviendo de forma aleatoria el orden de las imágenes\n",
    "random.shuffle(imagePaths_train)\n",
    "random.shuffle(imagePaths_validation)\n",
    "\n",
    "#Obteniendo la etiqueta de la imagen\n",
    "labels_train = [p.split(os.path.sep)[-2] for p in imagePaths_train]\n",
    "#Códificando las etiquetas en númerops\n",
    "le = LabelEncoder()\n",
    "labels_train = le.fit_transform(labels_train)\n",
    "\n",
    "#Obteniendo la etiqueta de la imagen\n",
    "labels_validation = [p.split(os.path.sep)[-2] for p in imagePaths_validation]\n",
    "#Códificando las etiquetas en númerops\n",
    "le = LabelEncoder()\n",
    "labels_validation = le.fit_transform(labels_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creando el modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_size,img_size,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabando en disco las caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = HDF5DatasetWriter((len(imagePaths_train), 1280 * 7 * 7), #es igual al tamaño de la última capa\n",
    "                            path_output_train_hdf5,\n",
    "                            dataKey = \"features\",\n",
    "                            bufSize = buffer_size)\n",
    "dataset_train.storeClassLabels(le.classes_)\n",
    "\n",
    "dataset_validation = HDF5DatasetWriter((len(imagePaths_validation), 1280 * 7 * 7), #es igual al tamaño de la última capa\n",
    "                            path_output_validation_hdf5,\n",
    "                            dataKey = \"features\",\n",
    "                            bufSize = buffer_size)\n",
    "dataset_validation.storeClassLabels(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obteniendo las caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracción de características: 100% |###########################| Time: 0:00:10\n"
     ]
    }
   ],
   "source": [
    "widgets = [\"Extracción de características: \",\n",
    "           progressbar.Percentage(),\n",
    "           \" \",\n",
    "           progressbar.Bar(),\n",
    "           \" \",\n",
    "           progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=len(imagePaths_train),\n",
    "                               widgets=widgets).start()\n",
    "\n",
    "# recorriendo el array con una distancia del batch_size\n",
    "for i in np.arange(0, len(imagePaths_train), batch_size):\n",
    "    # obteniendo los paths y labels de las imágenes\n",
    "    batchPaths = imagePaths_train[i:i + batch_size]\n",
    "    batchLabels = labels_train[i:i + batch_size]\n",
    "    batchImages = []\n",
    "    # recorremos el bath obtenido\n",
    "    for (j, imagePath) in enumerate(batchPaths):\n",
    "        #cargamos las imagenes con keras\n",
    "        image = load_img(imagePath, target_size=(img_size, img_size))\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        #hacemos un pre-procesamiento de la imagen\n",
    "        #le agregamos una dimensión\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        #obteniendo la media de la intesidad RGB del pixel\n",
    "        image = imagenet_utils.preprocess_input(image)\n",
    "        \n",
    "        #agregando la imagen al batch\n",
    "        batchImages.append(image)\n",
    "        \n",
    "    #creamos un stack con el array\n",
    "    batchImages = np.vstack(batchImages)\n",
    "    features = model.predict(batchImages, batch_size=batch_size)\n",
    "    \n",
    "    #hacemos un reshape de la predicción, convirtiendolo en 1D\n",
    "    features = features.reshape((features.shape[0], 1280 * 7 * 7))\n",
    "    \n",
    "    #agregamps los features en  el HDF5\n",
    "    dataset_train.add(features, batchLabels)\n",
    "    pbar.update(i)\n",
    "        \n",
    "#cerramos el  HDF5\n",
    "dataset_train.close()\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracción de características: 100% |###########################| Time: 0:00:08\n"
     ]
    }
   ],
   "source": [
    "widgets = [\"Extracción de características: \",\n",
    "           progressbar.Percentage(),\n",
    "           \" \",\n",
    "           progressbar.Bar(),\n",
    "           \" \",\n",
    "           progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=len(imagePaths_validation),\n",
    "                               widgets=widgets).start()\n",
    "\n",
    "# recorriendo el array con una distancia del batch_size\n",
    "for i in np.arange(0, len(imagePaths_validation), batch_size):\n",
    "    # obteniendo los paths y labels de las imágenes\n",
    "    batchPaths = imagePaths_validation[i:i + batch_size]\n",
    "    batchLabels = labels_validation[i:i + batch_size]\n",
    "    batchImages = []\n",
    "    # recorremos el bath obtenido\n",
    "    for (j, imagePath) in enumerate(batchPaths):\n",
    "        #cargamos las imagenes con keras\n",
    "        image = load_img(imagePath, target_size=(img_size, img_size))\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        #hacemos un pre-procesamiento de la imagen\n",
    "        #le agregamos una dimensión\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        #obteniendo la media de la intesidad RGB del pixel\n",
    "        image = imagenet_utils.preprocess_input(image)\n",
    "        \n",
    "        #agregando la imagen al batch\n",
    "        batchImages.append(image)\n",
    "        \n",
    "    #creamos un stack con el array\n",
    "    batchImages = np.vstack(batchImages)\n",
    "    features = model.predict(batchImages, batch_size=batch_size)\n",
    "    \n",
    "    #hacemos un reshape de la predicción, convirtiendolo en 1D\n",
    "    features = features.reshape((features.shape[0], 1280 * 7 * 7))\n",
    "    \n",
    "    #agregamps los features en  el HDF5\n",
    "    dataset_validation.add(features, batchLabels)\n",
    "    pbar.update(i)\n",
    "        \n",
    "#cerramos el  HDF5\n",
    "dataset_validation.close()\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenando el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import argparse\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos el HDF5\n",
    "db_train = h5py.File(path_output_train_hdf5, 'r')\n",
    "db_validation = h5py.File(path_output_validation_hdf5, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2240, 62720)\n",
      "(2240,)\n"
     ]
    }
   ],
   "source": [
    "print(db_train[\"features\"].shape)\n",
    "print(db_train[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] entrenando el modelo...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', probability=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entrenamos nuestro modelo usando las caracteristicas 128-d\n",
    "# luego reproduce el reconocimiento facial\n",
    "print(\"[INFO] entrenando el modelo...\")\n",
    "recognizer = SVC(C=1.0, kernel=\"linear\", probability=True)\n",
    "recognizer.fit(db_train[\"features\"], db_train[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluando el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.23      0.28      0.26       477\n",
      "         100       0.34      0.29      0.31       584\n",
      "          20       0.21      0.48      0.29       485\n",
      "         200       0.55      0.27      0.36       583\n",
      "          50       0.51      0.17      0.25       542\n",
      "\n",
      "    accuracy                           0.29      2671\n",
      "   macro avg       0.37      0.30      0.29      2671\n",
      "weighted avg       0.38      0.29      0.30      2671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = recognizer.predict(db_validation[\"features\"])\n",
    "print(classification_report(db_validation[\"labels\"], preds, target_names=db_validation[\"label_names\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_output = 'machine_learning/svc_mobilenet.pickle'\n",
    "labels_ouput = 'machine_learning/svc_labels.pickle'\n",
    "\n",
    "# grabamos en disco nuestro modelo\n",
    "f = open(model_output, \"wb\")\n",
    "f.write(pickle.dumps(recognizer))\n",
    "f.close()\n",
    "# write the label encoder to disk\n",
    "f = open(labels_ouput, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
